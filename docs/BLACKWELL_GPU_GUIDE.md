# RTX 50 ç³»åˆ— GPUï¼ˆBlackwell æ¶æ„ï¼‰å®Œæ•´æŒ‡å—

## ğŸ“Œ å¿«é€Ÿæ¦‚è§ˆ

**é€‚ç”¨èŒƒå›´**ï¼šRTX 5090, RTX 5080, RTX 5070 Ti, RTX 5070 ç­‰æ‰€æœ‰ Blackwell æ¶æ„ GPU

**æ ¸å¿ƒé—®é¢˜**ï¼šRTX 50 ç³»åˆ—ä½¿ç”¨å…¨æ–°çš„ Blackwell æ¶æ„ï¼ˆè®¡ç®—èƒ½åŠ› sm_120ï¼‰ï¼Œå¤§å¤šæ•°ç°æœ‰çš„ CUDA æ‰©å±•é»˜è®¤ä¸æ”¯æŒæ­¤æ¶æ„ï¼Œéœ€è¦ç‰¹æ®Šé…ç½®ã€‚

**å…³é”®è¦æ±‚**ï¼š
- CUDA 12.8+
- PyTorch 2.7+ with cu128
- æ‰€æœ‰ CUDA æ‰©å±•å¿…é¡»é’ˆå¯¹ sm_120 ç¼–è¯‘

---

## ğŸ¯ æ ¸å¿ƒé—®é¢˜è¯´æ˜

### ä»€ä¹ˆæ˜¯ Blackwell æ¶æ„ï¼Ÿ

Blackwell æ˜¯ NVIDIA 2025 å¹´å‘å¸ƒçš„æœ€æ–° GPU æ¶æ„ï¼Œç›¸æ¯”å‰ä»£ï¼š
- **è®¡ç®—èƒ½åŠ›**ï¼šsm_120ï¼ˆ12.0ï¼‰
- **å‰ä»£æ¶æ„**ï¼šAda (sm_89), Ampere (sm_86)
- **ç‰¹ç‚¹**ï¼šå…¨æ–°çš„æµå¤„ç†å™¨è®¾è®¡ï¼Œä¸å…¼å®¹æ—§çš„ CUDA äºŒè¿›åˆ¶

### ä¸ºä»€ä¹ˆä¼šå‡ºç°é”™è¯¯ï¼Ÿ

**å…¸å‹é”™è¯¯ä¿¡æ¯**ï¼š
```
CUDA kernel failed : no kernel image is available for execution on the device
```

æˆ–ï¼š
```
NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible
with the current PyTorch installation.
```

**åŸå› **ï¼š
1. CUDA æ‰©å±•ç¼–è¯‘æ—¶æœªåŒ…å« sm_120 æ¶æ„
2. PyTorch ç‰ˆæœ¬è¿‡æ—§ï¼Œä¸æ”¯æŒ Blackwell
3. CUDA Toolkit ç‰ˆæœ¬ä½äº 12.8

---

## âœ… å®Œæ•´è§£å†³æ–¹æ¡ˆ

### æ­¥éª¤ 1ï¼šéªŒè¯ç³»ç»Ÿè¦æ±‚

#### 1.1 æ£€æŸ¥ GPU
```bash
nvidia-smi --query-gpu=name,compute_cap --format=csv
```

**é¢„æœŸè¾“å‡º**ï¼š
```
name, compute_cap
NVIDIA GeForce RTX 5070 Ti, 12.0
```

å¦‚æœ compute_cap æ˜¯ 12.0ï¼Œè¯´æ˜æ˜¯ Blackwell æ¶æ„ã€‚

#### 1.2 æ£€æŸ¥ CUDA ç‰ˆæœ¬
```bash
nvcc --version
```

**è¦æ±‚**ï¼šCUDA 12.8 æˆ–æ›´é«˜

**å¦‚æœç‰ˆæœ¬è¿‡ä½**ï¼š
```bash
# ä½¿ç”¨é‡è£…è„šæœ¬
./scripts/cuda_reinstall.sh

# æˆ–æ‰‹åŠ¨å®‰è£…
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get install -y cuda-toolkit-12-8
```

#### 1.3 é…ç½®ç¯å¢ƒå˜é‡
```bash
# æ·»åŠ åˆ° .bashrc
echo 'export PATH=/usr/local/cuda-12.8/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.8/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

### æ­¥éª¤ 2ï¼šå®‰è£…æ­£ç¡®çš„ PyTorch

#### 2.1 å¸è½½æ—§ç‰ˆæœ¬ï¼ˆå¦‚æœ‰ï¼‰
```bash
uv pip uninstall torch torchvision torchaudio
```

#### 2.2 å®‰è£… PyTorch cu128 ç‰ˆæœ¬
```bash
# ç¨³å®šç‰ˆï¼ˆæ¨èï¼‰
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# æˆ– Nightly ç‰ˆæœ¬ï¼ˆæœ€æ–°ç‰¹æ€§ï¼‰
uv pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
```

#### 2.3 éªŒè¯ PyTorch
```bash
python -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA version: {torch.version.cuda}')
print(f'GPU: {torch.cuda.get_device_name(0)}')
print(f'Supported architectures: {torch.cuda.get_arch_list()}')
"
```

**é¢„æœŸè¾“å‡º**ï¼š
```
PyTorch: 2.8.0+cu128
CUDA available: True
CUDA version: 12.8
GPU: NVIDIA GeForce RTX 5070 Ti
Supported architectures: ['sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90', 'sm_100', 'sm_120']
```

**å…³é”®**ï¼š`sm_120` å¿…é¡»åœ¨æ”¯æŒåˆ—è¡¨ä¸­ï¼

### æ­¥éª¤ 3ï¼šå®‰è£… torchmcubesï¼ˆé’ˆå¯¹ Blackwellï¼‰

#### 3.1 ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬ï¼ˆæ¨èï¼‰
```bash
cd /home/doer/repos/TripoSR
./scripts/safe_install_torchmcubes.sh
```

è¯¥è„šæœ¬ä¼šï¼š
- è‡ªåŠ¨æ£€æµ‹ RTX 5070 Ti
- åŒ…å« sm_120 æ¶æ„ç¼–è¯‘
- è‡ªåŠ¨å®‰è£…æ‰€æœ‰ä¾èµ–

#### 3.2 æ‰‹åŠ¨å®‰è£…ï¼ˆå¦‚æœè„šæœ¬å¤±è´¥ï¼‰
```bash
# å®‰è£…æ„å»ºä¾èµ–
uv pip install scikit-build-core cmake ninja pybind11

# è®¾ç½®ç¯å¢ƒå˜é‡
export MAX_JOBS=2
export TORCH_CUDA_ARCH_LIST="7.0;7.5;8.0;8.6;8.9;9.0;10.0;12.0"
export CFLAGS="-O2"
export CXXFLAGS="-O2"

# å¸è½½æ—§ç‰ˆæœ¬
uv pip uninstall torchmcubes

# ç¼–è¯‘å®‰è£…
uv pip install --no-cache-dir --no-build-isolation \
    git+https://github.com/tatsy/torchmcubes.git
```

**å…³é”®ç‚¹**ï¼š`TORCH_CUDA_ARCH_LIST` å¿…é¡»åŒ…å« `12.0`ï¼ˆå¯¹åº” sm_120ï¼‰

#### 3.3 éªŒè¯å®‰è£…
```bash
python -c "
import torch
import torchmcubes
from torchmcubes import marching_cubes

print('torchmcubes å®‰è£…æˆåŠŸï¼')
print(f'CUDA support: {torch.cuda.is_available()}')

# å¿«é€Ÿæµ‹è¯•
if torch.cuda.is_available():
    print('æ­£åœ¨æµ‹è¯• CUDA åŠŸèƒ½...')
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    voxels = torch.randn(32, 32, 32).cuda()
    verts, faces = marching_cubes(voxels, 0.0)
    print(f'æµ‹è¯•æˆåŠŸï¼ç”Ÿæˆ {len(verts)} ä¸ªé¡¶ç‚¹')
"
```

### æ­¥éª¤ 4ï¼šæµ‹è¯• TripoSR
```bash
cd /home/doer/repos/TripoSR
python run.py examples/chair.png --output-dir output/
```

**æˆåŠŸæ ‡å¿—**ï¼š
```
2025-10-13 22:12:43,423 - INFO - Extracting mesh ...
2025-10-13 22:12:43,506 - INFO - Exporting mesh finished in 83.20ms.
```

è¾“å‡ºæ–‡ä»¶ï¼š`output/0/mesh.obj`

---

## ğŸ”§ å¸¸è§é—®é¢˜

### é—®é¢˜ 1ï¼šç¼–è¯‘æ—¶å‡ºç° "no kernel image available"

**åŸå› **ï¼štorchmcubes æœªé’ˆå¯¹ sm_120 ç¼–è¯‘

**è§£å†³**ï¼š
```bash
# ç¡®ä¿åŒ…å« sm_120
export TORCH_CUDA_ARCH_LIST="7.0;7.5;8.0;8.6;8.9;9.0;10.0;12.0"
uv pip uninstall torchmcubes
uv pip install --no-cache-dir --no-build-isolation git+https://github.com/tatsy/torchmcubes.git
```

### é—®é¢˜ 2ï¼šPyTorch ä¸æ”¯æŒ sm_120

**æ£€æŸ¥**ï¼š
```bash
python -c "import torch; print(torch.cuda.get_arch_list())"
```

**å¦‚æœæ²¡æœ‰ sm_120**ï¼š
```bash
# é‡è£… PyTorch cu128
uv pip uninstall torch torchvision torchaudio
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```

### é—®é¢˜ 3ï¼šnvcc ç‰ˆæœ¬ä½äº 12.8

**è§£å†³**ï¼š
```bash
# ä½¿ç”¨å®Œå…¨é‡è£…è„šæœ¬
./scripts/cuda_reinstall.sh
```

### é—®é¢˜ 4ï¼šç¼–è¯‘æ—¶ç¼ºå°‘ CMakeã€pybind11 ç­‰ä¾èµ–

**ç—‡çŠ¶**ï¼š
```
ModuleNotFoundError: No module named 'scikit_build_core'
CMakeNotFoundError: Could not find CMake with version >=3.15
Could not find a package configuration file provided by "pybind11"
```

**è§£å†³**ï¼š
```bash
uv pip install scikit-build-core cmake ninja pybind11
```

`safe_install_torchmcubes.sh` v2.0 ä¼šè‡ªåŠ¨å®‰è£…è¿™äº›ä¾èµ–ã€‚

### é—®é¢˜ 5ï¼šWSL2 åœ¨ç¼–è¯‘æ—¶å´©æºƒ

**åŸå› **ï¼šå†…å­˜ä¸è¶³

**è§£å†³**ï¼š
1. é…ç½® WSL2 å†…å­˜ï¼ˆå‚è€ƒ `docs/WSL2_ML_OPTIMIZATION.md`ï¼‰
2. ç¼–è¾‘ `C:\Users\<ç”¨æˆ·å>\.wslconfig`ï¼š
```ini
[wsl2]
memory=50GB
processors=24
swap=20GB
```
3. é‡å¯ WSL2ï¼š
```powershell
# Windows PowerShell
wsl --shutdown
```

---

## ğŸ“Š æ¶æ„å¯¹ç…§è¡¨

| GPU ç³»åˆ— | æ¶æ„åç§° | è®¡ç®—èƒ½åŠ› | CUDA è¦æ±‚ | PyTorch è¦æ±‚ |
|---------|---------|---------|----------|--------------|
| RTX 50xx | Blackwell | sm_120 (12.0) | 12.8+ | 2.7+ cu128 |
| RTX 40xx | Ada | sm_89 (8.9) | 11.8+ | 2.0+ cu118 |
| RTX 30xx | Ampere | sm_86 (8.6) | 11.0+ | 1.7+ cu110 |
| RTX 20xx | Turing | sm_75 (7.5) | 10.0+ | 1.0+ cu100 |

**æ³¨æ„**ï¼šæ¯ä¸ªæ¶æ„ä½¿ç”¨ä¸åŒçš„ CUDA äºŒè¿›åˆ¶æ ¼å¼ï¼Œå¿…é¡»é’ˆå¯¹ç›®æ ‡æ¶æ„ç¼–è¯‘ï¼

---

## ğŸš€ æœ€ä½³å®è·µ

### 1. ç¼–è¯‘ CUDA æ‰©å±•çš„é€šç”¨æ¨¡æ¿

å¯¹äºä»»ä½•éœ€è¦ CUDA çš„ Python åŒ…ï¼š

```bash
# è®¾ç½®é€šç”¨ç¯å¢ƒå˜é‡
export MAX_JOBS=2  # é™åˆ¶å¹¶è¡Œç¼–è¯‘ï¼Œé¿å…å†…å­˜æº¢å‡º
export TORCH_CUDA_ARCH_LIST="7.0;7.5;8.0;8.6;8.9;9.0;10.0;12.0"
export CFLAGS="-O2"
export CXXFLAGS="-O2"

# æ¸…ç†ç¼“å­˜
uv cache clean

# ç¼–è¯‘å®‰è£…
uv pip install --no-cache-dir --no-build-isolation <package>
```

### 2. éªŒè¯ CUDA æ‰©å±•çš„æ¶æ„æ”¯æŒ

```bash
# æŸ¥çœ‹å·²å®‰è£…åŒ…çš„æ¶æ„æ”¯æŒ
python -c "
import torch
print('PyTorch æ”¯æŒçš„æ¶æ„:', torch.cuda.get_arch_list())

# æ£€æŸ¥å½“å‰ GPU æ¶æ„
if torch.cuda.is_available():
    cap = torch.cuda.get_device_capability()
    sm = f'sm_{cap[0]}{cap[1]}'
    print(f'å½“å‰ GPU æ¶æ„: {sm}')

    if sm in torch.cuda.get_arch_list():
        print('âœ“ PyTorch æ”¯æŒå½“å‰ GPU')
    else:
        print('âœ— PyTorch ä¸æ”¯æŒå½“å‰ GPU - éœ€è¦é‡è£…ï¼')
"
```

### 3. é¡¹ç›®ç¯å¢ƒæ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹ä»»ä½• CUDA é¡¹ç›®å‰ï¼š

```bash
# åˆ›å»ºæ£€æŸ¥è„šæœ¬
cat > check_cuda_env.sh << 'EOF'
#!/bin/bash
echo "=== CUDA ç¯å¢ƒæ£€æŸ¥ ==="
echo ""

echo "1. GPU ä¿¡æ¯ï¼š"
nvidia-smi --query-gpu=name,compute_cap,memory.total --format=csv
echo ""

echo "2. CUDA ç‰ˆæœ¬ï¼š"
nvcc --version | grep release
echo ""

echo "3. PyTorch ä¿¡æ¯ï¼š"
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.version.cuda}'); print(f'cuDNN: {torch.backends.cudnn.version()}'); print(f'æ”¯æŒçš„æ¶æ„: {torch.cuda.get_arch_list()}')"
echo ""

echo "4. GPU å¯ç”¨æ€§ï¼š"
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'Device count: {torch.cuda.device_count()}'); print(f'Current device: {torch.cuda.current_device() if torch.cuda.is_available() else \"N/A\"}')"
EOF

chmod +x check_cuda_env.sh
./check_cuda_env.sh
```

---

## ğŸ”— ç›¸å…³èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [NVIDIA CUDA on WSL](https://docs.nvidia.com/cuda/wsl-user-guide/)
- [PyTorch CUDA Installation](https://pytorch.org/get-started/locally/)
- [CUDA Compute Capability](https://developer.nvidia.com/cuda-gpus)

### æœ¬é¡¹ç›®æ–‡æ¡£
- [`SESSION_SUMMARY.md`](../SESSION_SUMMARY.md) - å®Œæ•´é—®é¢˜è§£å†³è¿‡ç¨‹
- [`WSL2_ML_OPTIMIZATION.md`](WSL2_ML_OPTIMIZATION.md) - WSL2 å¤§æ¨¡å‹è®­ç»ƒä¼˜åŒ–
- [`WSL2_CRASH_SOLUTION.md`](WSL2_CRASH_SOLUTION.md) - WSL2 å´©æºƒé—®é¢˜è§£å†³

### è„šæœ¬å·¥å…·
- [`scripts/safe_install_torchmcubes.sh`](../scripts/safe_install_torchmcubes.sh) - torchmcubes è‡ªåŠ¨åŒ–å®‰è£…
- [`scripts/cuda_reinstall.sh`](../scripts/cuda_reinstall.sh) - CUDA å®Œå…¨é‡è£…
- [`scripts/wsl_performance_monitor.sh`](../scripts/wsl_performance_monitor.sh) - æ€§èƒ½ç›‘æ§

---

## ğŸ’¡ æ€»ç»“

### RTX 50 ç³»åˆ—æ ¸å¿ƒè¦ç‚¹

1. **å¿…é¡»ä½¿ç”¨ CUDA 12.8+**
2. **å¿…é¡»ä½¿ç”¨ PyTorch cu128 ç‰ˆæœ¬**
3. **æ‰€æœ‰ CUDA æ‰©å±•å¿…é¡»åŒ…å« sm_120 ç¼–è¯‘**
4. **ç¼–è¯‘æ—¶è®¾ç½® `TORCH_CUDA_ARCH_LIST` åŒ…å« `12.0`**

### å¿«é€Ÿå‘½ä»¤å‚è€ƒ

```bash
# å®Œæ•´å®‰è£…æµç¨‹ï¼ˆä»é›¶å¼€å§‹ï¼‰
./scripts/cuda_reinstall.sh                    # 1. é‡è£… CUDA 12.8
uv pip install torch torchvision --index-url https://download.pytorch.org/whl/cu128  # 2. å®‰è£… PyTorch
./scripts/safe_install_torchmcubes.sh          # 3. å®‰è£… torchmcubes
python run.py examples/chair.png --output-dir output/  # 4. æµ‹è¯•

# éªŒè¯å‘½ä»¤
nvidia-smi                                      # GPU çŠ¶æ€
nvcc --version                                  # CUDA ç‰ˆæœ¬
python -c "import torch; print(torch.cuda.get_arch_list())"  # PyTorch æ¶æ„æ”¯æŒ
```

### æ•…éšœæ’é™¤ä¼˜å…ˆçº§

1. **ç¡®è®¤ GPU æ¶æ„**ï¼š`nvidia-smi --query-gpu=compute_cap --format=csv`
2. **ç¡®è®¤ CUDA ç‰ˆæœ¬**ï¼š`nvcc --version` â‰¥ 12.8
3. **ç¡®è®¤ PyTorch ç‰ˆæœ¬**ï¼š`python -c "import torch; print(torch.version.cuda)"` = 12.8
4. **ç¡®è®¤æ¶æ„æ”¯æŒ**ï¼š`python -c "import torch; print('sm_120' in str(torch.cuda.get_arch_list()))"`
5. **é‡æ–°ç¼–è¯‘æ‰©å±•**ï¼šåŒ…å« `TORCH_CUDA_ARCH_LIST="12.0"`

---

**æœ€åæ›´æ–°**ï¼š2025-10-13
**æ–‡æ¡£ç‰ˆæœ¬**ï¼š1.0
**æµ‹è¯•ç¯å¢ƒ**ï¼šRTX 5070 Ti, CUDA 12.8, PyTorch 2.8.0+cu128, WSL2 Ubuntu 22.04
