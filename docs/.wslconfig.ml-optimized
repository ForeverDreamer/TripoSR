# ╔════════════════════════════════════════════════════════════════╗
# ║   WSL2 高性能配置 - 针对大模型训练和推理优化                   ║
# ║   硬件: 64GB RAM, i9-13900KF (24核32线程), RTX 5070 Ti 16GB   ║
# ║   优化目标: 最大化AI/ML性能，同时保证Windows稳定性             ║
# ╚════════════════════════════════════════════════════════════════╝

[wsl2]

# ═══════════════════════════════════════════════════════════════
# 核心资源分配 (78% 资源给 WSL2)
# ═══════════════════════════════════════════════════════════════

# 内存分配: 50GB (保留14GB给Windows确保稳定性)
# 推荐值: 物理内存的 75-80%
# 大模型训练时可能需要 32-48GB，此配置提供充足空间
memory=50GB

# CPU核心: 24个处理器 (保留8个给Windows)
# 对于数据预处理和多进程训练非常重要
processors=24

# Swap空间: 20GB
# 防止大模型加载时内存溢出 (OOM)
# 建议: 内存分配的 30-40%
swap=20GB

# ═══════════════════════════════════════════════════════════════
# 内存管理优化 (WSL 2.2.4+ 新特性)
# ═══════════════════════════════════════════════════════════════

# 自动内存回收: gradual 模式
# - gradual: 逐步释放未使用内存回Windows (推荐用于训练)
# - dropcache: 立即释放页面缓存 (适合推理)
# - disabled: 不自动回收 (最大性能但占用内存)
autoMemoryReclaim=gradual

# VM空闲超时: 60秒
# WSL空闲1分钟后开始逐步释放内存
# 训练任务时几乎不会触发，保证持续高性能
vmIdleTimeout=60000

# ═══════════════════════════════════════════════════════════════
# 存储优化
# ═══════════════════════════════════════════════════════════════

# 稀疏VHD: 启用
# 自动压缩WSL2虚拟磁盘，回收删除文件的空间
# 训练时产生大量临时文件，此选项可节省磁盘空间
sparseVhd=true

# 页面报告: 启用
# 提高内存分配效率，减少虚拟化开销
pageReporting=true

# 猜测VHD大小: 启用
# 优化虚拟磁盘扩展性能
guessVhdSize=true

# ═══════════════════════════════════════════════════════════════
# 虚拟化和硬件支持
# ═══════════════════════════════════════════════════════════════

# 嵌套虚拟化: 启用
# 支持在WSL2中运行Docker等容器技术
# 大模型训练常用Docker部署
nestedVirtualization=true

# ═══════════════════════════════════════════════════════════════
# 网络优化
# ═══════════════════════════════════════════════════════════════

# Localhost转发: 启用
# 确保WSL2的端口可以从Windows访问
# 用于TensorBoard、Jupyter等Web服务
localhostForwarding=true

# ═══════════════════════════════════════════════════════════════
# Linux内核参数优化
# ═══════════════════════════════════════════════════════════════

# 关键内核参数调优:
# - vm.swappiness=10: 尽量使用物理内存，减少swap使用
# - vm.max_map_count=262144: 增加内存映射限制（大模型需要）
# - vm.overcommit_memory=1: 允许内存过量分配
# - fs.inotify.max_user_watches=524288: 增加文件监视数量
# - kernel.pid_max=4194304: 增加最大进程数
kernelCommandLine = sysctl.vm.swappiness=10 sysctl.vm.max_map_count=262144 sysctl.vm.overcommit_memory=1 sysctl.fs.inotify.max_user_watches=524288 sysctl.kernel.pid_max=4194304

# ═══════════════════════════════════════════════════════════════
# 调试和监控
# ═══════════════════════════════════════════════════════════════

# 调试控制台: 关闭 (生产环境)
debugConsole=false

# ═══════════════════════════════════════════════════════════════
# 性能调优说明
# ═══════════════════════════════════════════════════════════════
#
# 🎯 针对不同场景的微调建议:
#
# 1. 大模型训练 (当前配置):
#    - memory=50GB, processors=24, swap=20GB
#    - autoMemoryReclaim=gradual
#
# 2. 模型推理服务:
#    - memory=40GB, processors=20, swap=16GB
#    - autoMemoryReclaim=dropcache
#
# 3. 极限性能模式 (需要关闭大部分Windows程序):
#    - memory=56GB, processors=28, swap=24GB
#    - autoMemoryReclaim=disabled
#
# 4. 日常开发 (平衡模式):
#    - memory=32GB, processors=16, swap=16GB
#    - autoMemoryReclaim=gradual
#
# 💡 性能监控命令:
#    WSL内: free -h, htop, nvidia-smi
#    Windows: 任务管理器 -> 性能 -> Vmmem进程
#
# ⚠️ 注意事项:
#    - 修改后必须执行 "wsl --shutdown" 才能生效
#    - 首次启动WSL2会预分配部分内存
#    - 训练时监控Windows可用内存，确保不低于4GB
#
# ═══════════════════════════════════════════════════════════════

